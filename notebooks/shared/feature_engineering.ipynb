{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nUTILITY FUNCTIONS\\n'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "This is a boilerplate pipeline 'data_processing'\n",
    "generated using Kedro 0.18.3\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "\"\"\"\n",
    "UTILITY FUNCTIONS\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the datasets \n",
    "busstops = pd.read_csv('C:/Users/aminp/OneDrive/Dokumenter/NTNU/4år/Machinelearning/machine_learning/data/raw/busstops_norway.csv')\n",
    "grunnkrets_age = pd.read_csv('C:/Users/aminp/OneDrive/Dokumenter/NTNU/4år/Machinelearning/machine_learning/data/raw/grunnkrets_age_distribution.csv')\n",
    "grunnkrets_household = pd.read_csv('C:/Users/aminp/OneDrive/Dokumenter/NTNU/4år/Machinelearning/machine_learning/data/raw/grunnkrets_households_num_persons.csv')\n",
    "grunnkrets_income = pd.read_csv('C:/Users/aminp/OneDrive/Dokumenter/NTNU/4år/Machinelearning/machine_learning/data/raw/grunnkrets_income_households.csv')\n",
    "grunnkrets_norway = pd.read_csv('C:/Users/aminp/OneDrive/Dokumenter/NTNU/4år/Machinelearning/machine_learning/data/raw/grunnkrets_norway_stripped.csv')\n",
    "plaace_hierarchy = pd.read_csv('C:/Users/aminp/OneDrive/Dokumenter/NTNU/4år/Machinelearning/machine_learning/data/raw/plaace_hierarchy.csv')\n",
    "sample_submission = pd.read_csv('C:/Users/aminp/OneDrive/Dokumenter/NTNU/4år/Machinelearning/machine_learning/data/raw/sample_submission.csv')\n",
    "stores_extra = pd.read_csv('C:/Users/aminp/OneDrive/Dokumenter/NTNU/4år/Machinelearning/machine_learning/data/raw/stores_extra.csv')\n",
    "stores_test = pd.read_csv('C:/Users/aminp/OneDrive/Dokumenter/NTNU/4år/Machinelearning/machine_learning/data/raw/stores_test.csv')\n",
    "stores_train = pd.read_csv('C:/Users/aminp/OneDrive/Dokumenter/NTNU/4år/Machinelearning/machine_learning/data/raw/stores_train.csv')\n",
    "simens_df = pd.read_csv(\"C:/Users/aminp/OneDrive/Dokumenter/NTNU/4år/Machinelearning/machine_learning/notebooks/simen/simens_dataframe-1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impude_NaN (stores_df, grunnkrets_df, NaN_string ): \n",
    "    geo_df = grunnkrets_df[grunnkrets_df[\"year\"] == 2016]\n",
    "    geo_df2 = geo_df.drop(\"year\", axis = 1)\n",
    "    merged_df = stores_df.merge(geo_df2, how = \"left\", on = \"grunnkrets_id\")\n",
    "    NaN_df = merged_df[merged_df[NaN_string].isna()]\n",
    "    split_df = merged_df[merged_df[NaN_string].notna()]\n",
    "\n",
    "    mat = cdist(NaN_df[['lat', 'lon']],\n",
    "                split_df[['lat', 'lon']], metric='euclidean')\n",
    "\n",
    "    new_df = pd.DataFrame(mat, index= NaN_df['grunnkrets_id'], columns=split_df['grunnkrets_id'])\n",
    "\n",
    "    grunnkrets_id = NaN_df.grunnkrets_id\n",
    "    closest = new_df.idxmin(axis=1)\n",
    "    distance = new_df.min(axis=1)\n",
    "\n",
    "    closest_df_with_distance = pd.DataFrame({\"grunnkrets_id\": grunnkrets_id, \"closest_valid_id\" : closest.values, \"distance\": distance.values})\n",
    "    closest_df = pd.DataFrame({\"grunnkrets_id\": grunnkrets_id, \"closest_valid_id\" : closest.values})\n",
    "\n",
    "    df_with_values_from_valid_id = split_df[split_df[\"grunnkrets_id\"].isin(closest.values)]\n",
    "    df_with_values_from_valid_id_removed_duplicates = df_with_values_from_valid_id.drop_duplicates(subset = [\"grunnkrets_id\"])\n",
    "\n",
    "    df_valid_geo_data = df_with_values_from_valid_id_removed_duplicates.iloc[:,12:]\n",
    "    df_with_only_gk_id = df_with_values_from_valid_id_removed_duplicates[[\"grunnkrets_id\"]]\n",
    "    df_list = [df_with_only_gk_id,df_valid_geo_data ]\n",
    "    df_valid_geo_data_and_id = pd.concat(df_list, axis=1)\n",
    "\n",
    "    df_without_nan = NaN_df.iloc[:,:12]\n",
    "\n",
    "    df_including_closest_valid_id = df_without_nan.reset_index().merge(closest_df, how = \"left\", on = \"grunnkrets_id\").set_index(\"index\")\n",
    "\n",
    "    df_impuded = df_including_closest_valid_id.reset_index().merge(df_valid_geo_data_and_id, how=\"left\", left_on =\"closest_valid_id\", right_on=\"grunnkrets_id\").set_index(\"index\")\n",
    "    df_impuded_without_duplicates = df_impuded.drop_duplicates(subset=\"store_id\")\n",
    "\n",
    "    new_df_impuded = df_impuded_without_duplicates.drop([\"closest_valid_id\", \"grunnkrets_id_y\"], axis = 1).rename(columns= {\"grunnkrets_id_x\": \"grunnkrets_id\"})\n",
    "\n",
    "\n",
    "    impuded = pd.concat([split_df, new_df_impuded])\n",
    "\n",
    "    return impuded\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores_gk_impuded = impude_NaN(stores_train, grunnkrets_norway, NaN_string=\"district_name\")\n",
    "stores_house_impuded = impude_NaN(stores_train, grunnkrets_household, \"singles\")\n",
    "stores_age_impuded = impude_NaN(stores_train, grunnkrets_age, NaN_string=\"age_0\")\n",
    "\n",
    "def population_age_impuded(age_impuded_df):\n",
    "    age_part = age_impuded_df.iloc[:,12:]\n",
    "    age_gk_id = age_impuded_df[[\"grunnkrets_id\"]]\n",
    "    age_df = pd.concat([age_gk_id, age_part], axis = 1)\n",
    "    population = age_df.drop([\"grunnkrets_id\"], axis=1).sum(axis=1)\n",
    "    age_df[\"population_count\"] = population\n",
    "    return age_df[[\"grunnkrets_id\", \"population_count\"]]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "UTILITY FUNCTIONS\n",
    "\"\"\"\n",
    "# This function calculates the population for each grunnkrets\n",
    "# Returns a df with grunnkretsID in the first column and population_count in the second column\n",
    "\n",
    "\n",
    "def population(age):\n",
    "    age_df = age[age[\"year\"] == 2016]\n",
    "    population = age_df.drop([\"grunnkrets_id\" ,\"year\"], axis=1).sum(axis=1)\n",
    "    age_df[\"population_count\"] = population\n",
    "    return age_df[[\"grunnkrets_id\", \"population_count\"]]\n",
    "\n",
    "# This function calculates the population in a district or municipality, by setting grouping_elemnt either to the district_name or municipality_name\n",
    "\n",
    "\n",
    "def population_grouped(data_age, data_geography, grouping_element):\n",
    "    age_df = population(data_age)\n",
    "    geography_df = data_geography[data_geography[\"year\"] == 2016]\n",
    "    population_df = age_df.merge(geography_df, how=\"inner\", on=\"grunnkrets_id\")\n",
    "    grouped_df = population_df.groupby([grouping_element], as_index=False)[\n",
    "        \"population_count\"].sum()\n",
    "    return grouped_df\n",
    "\n",
    "# This function calculates the density (population/area_km2) for the chosen grouping_element\n",
    "\n",
    "\n",
    "def population_density(age_df, geo_df, grouping_element):\n",
    "    age_data = population(age_df)\n",
    "    geo_df = geo_df[geo_df[\"year\"] == 2016]\n",
    "    combined_df = age_data.merge(geo_df, how=\"left\", on=\"grunnkrets_id\")\n",
    "    density_df = combined_df.groupby([grouping_element], as_index=False)[\n",
    "        [\"population_count\", \"area_km2\"]].sum()\n",
    "    density_df[\"density\"] = density_df[\"population_count\"] / \\\n",
    "        density_df[\"area_km2\"]\n",
    "    return density_df\n",
    "\n",
    "# This function checks wether or not a store is part of a mall or not\n",
    "\n",
    "\n",
    "def is_mall(stores_df):\n",
    "    df = stores_df.copy()\n",
    "    df[\"is_mall\"] = df[\"mall_name\"].notna()\n",
    "    return df[[\"store_id\", \"mall_name\", \"is_mall\"]]\n",
    "\n",
    "# This function checks wether or not a store is part of a chain or not\n",
    "\n",
    "\n",
    "def is_chain(stores_df):\n",
    "    df = stores_df.copy()\n",
    "    df[\"is_chain\"] = df[\"chain_name\"].notna()\n",
    "    return df[[\"store_id\", \"chain_name\", \"is_chain\"]]\n",
    "\n",
    "# This function calculates the population count per number of stores in a geographic region\n",
    "\n",
    "\n",
    "def population_per_store(age_df, geo_df, stores_df, impuded_df, grouping_element):\n",
    "    new_geo_df = geo_df[geo_df[\"year\"] == 2016]\n",
    "    pop_gk = population(age_df)\n",
    "    pop_df = population_grouped(age_df, geo_df, grouping_element)\n",
    "    #combined_df = pop_gk.merge(stores_df, how=\"left\", on=\"grunnkrets_id\").merge(new_geo_df, how=\"left\", on=\"grunnkrets_id\")\n",
    "    combined_df = pop_gk.merge(impuded_df, how = \"left\", on = \"grunnkrets_id\")\n",
    "    grouped_df = combined_df.groupby([grouping_element], as_index=False)[\n",
    "        \"store_id\"].count()\n",
    "    pop_per_store_df = grouped_df.merge(\n",
    "        pop_df, how=\"inner\", on=grouping_element)\n",
    "    pop_per_store_df[\"population_per_num_stores\"] = pop_per_store_df[\"population_count\"] / \\\n",
    "        pop_per_store_df[\"store_id\"]\n",
    "    pop_per_store_df.rename(columns={\"store_id\": \"num_stores\"}, inplace=True)\n",
    "    new_pop_per_store_df = pop_per_store_df.replace([np.inf, -np.inf], 0)\n",
    "    return new_pop_per_store_df\n",
    "\n",
    "#This function do the same as population_per_store but can also filter on store types\n",
    "def population_per_store_types(stores_df, plaace_hierarchy, grunnkrets_df, age_df, impuded_df, agg_name, geo_group, store_type_group): \n",
    "    grunnkrets_df_2016 = grunnkrets_df[grunnkrets_df[\"year\"] == 2016]\n",
    "    num_stores_types_by_geo_group = store_types_count_by_geo_group(stores_df, plaace_hierarchy, grunnkrets_df_2016, impuded_df, agg_name, geo_group, store_type_group)\n",
    "    pop_grouped_by_geo = population_grouped(age_df, grunnkrets_df_2016, geo_group)\n",
    "    combined_df = num_stores_types_by_geo_group.merge(pop_grouped_by_geo, how = \"left\", on = geo_group)\n",
    "    combined_df[\"population_per_num_store\"] = combined_df[\"population_count\"] / combined_df[agg_name]\n",
    "    return combined_df\n",
    "\n",
    "# This function groups the age distrubution (0-90) into 7 buckets with and returns a table which represents the presentages each of these\n",
    "# buckets corresponds to compared with the total amount of people living in the given geographic region s\n",
    "\n",
    "\n",
    "def age_distrubution(grunnkrets_age_df, geographic_df, grouping_element):\n",
    "    age_df = grunnkrets_age_df[grunnkrets_age_df[\"year\"] == 2016]\n",
    "    age_df1 = age_df.drop([\"year\"], axis = 1)\n",
    "    age_df1[\"num_kids\"] = age_df1.iloc[:, 1:8].sum(axis=1)\n",
    "    age_df1[\"num_kids+\"] = age_df1.iloc[:, 8:14].sum(axis=1)\n",
    "    age_df1[\"num_youths\"] = age_df1.iloc[:, 14: 19].sum(axis=1)\n",
    "    age_df1[\"num_youthAdult\"] = age_df1.iloc[:, 19:27].sum(axis=1)\n",
    "    age_df1[\"num_adult\"] = age_df1.iloc[:, 27:37].sum(axis=1)\n",
    "    age_df1[\"num_adults+\"] = age_df1.iloc[:, 37:62].sum(axis=1)\n",
    "    age_df1[\"num_pensinors\"] = age_df1.iloc[:, 62:92].sum(axis=1)\n",
    "\n",
    "    age_df2 = age_df1[[\"grunnkrets_id\", \"num_kids\", \"num_kids+\", \"num_youths\",\n",
    "                       \"num_youthAdult\", \"num_adult\", \"num_adults+\", \"num_pensinors\"]]\n",
    "\n",
    "    pop_df = population(grunnkrets_age_df)\n",
    "    geo_df = geographic_df[geographic_df[\"year\"] == 2016]\n",
    "    new_geo_df = geo_df.drop([\"geometry\", \"area_km2\", \"year\"], axis=1)\n",
    "    combined_df = age_df2.merge(pop_df, how=\"left\", on=\"grunnkrets_id\").merge(\n",
    "        new_geo_df, how=\"left\", on=\"grunnkrets_id\")\n",
    "    list_columns = [\"num_kids\", \"num_kids+\", \"num_youths\",\n",
    "                    \"num_youthAdult\", \"num_adult\", \"num_adults+\", \"num_pensinors\"]\n",
    "    combined_df2 = combined_df.groupby([grouping_element], as_index=False)[\n",
    "        list_columns].sum()\n",
    "\n",
    "    pop_gk = population_grouped(\n",
    "        grunnkrets_age_df, geographic_df, grouping_element)\n",
    "    new_df = combined_df2.merge(pop_gk, how=\"left\", on=grouping_element)\n",
    "\n",
    "    new_df[\"kids_%\"] = new_df[\"num_kids\"] / new_df[\"population_count\"]\n",
    "    new_df[\"kids+_%\"] = new_df[\"num_kids+\"] / new_df[\"population_count\"]\n",
    "    new_df[\"youths_%\"] = new_df[\"num_youths\"] / new_df[\"population_count\"]\n",
    "    new_df[\"youthAdult_%\"] = new_df[\"num_youthAdult\"] / \\\n",
    "        new_df[\"population_count\"]\n",
    "    new_df[\"adult_%\"] = new_df[\"num_adult\"] / new_df[\"population_count\"]\n",
    "    new_df[\"adults+_%\"] = new_df[\"num_adults+\"] / new_df[\"population_count\"]\n",
    "    new_df[\"pensinors_%\"] = new_df[\"num_pensinors\"] / \\\n",
    "        new_df[\"population_count\"]\n",
    "\n",
    "    age_dist_df = new_df.drop([\"population_count\"], axis=1)\n",
    "    # if (grouping_element == \"grunnkrets_id\"):\n",
    "    # return new_df[[\"grunnkrets_id\", \"kids_%\", \"kids+_%\", \"youths_%\", \"youthAdult_%\", \"adult_%\", \"adults+_%\", \"pensinors_%\" ]]\n",
    "    # else:\n",
    "    # return new_df[[grouping_element, \"kids_%\", \"kids+_%\", \"youths_%\", \"youthAdult_%\", \"adult_%\", \"adults+_%\", \"pensinors_%\" ]]\n",
    "\n",
    "    return age_dist_df\n",
    "\n",
    "# This function calculates the total amount of household types based on a geographic area\n",
    "\n",
    "\n",
    "def household_type_distrubution(geographic_df, household_df, grouping_element):\n",
    "    house_df = household_df[household_df[\"year\"] == 2016]\n",
    "    geo_df = geographic_df[geographic_df[\"year\"] == 2016]\n",
    "    combined_df = geo_df.merge(house_df, how=\"inner\", on=\"grunnkrets_id\")\n",
    "\n",
    "    list_columns = [\"couple_children_0_to_5_years\", \"couple_children_18_or_above\", \"couple_children_6_to_17_years\",\n",
    "                    \"couple_without_children\", \"single_parent_children_0_to_5_years\", \"single_parent_children_18_or_above\",\n",
    "                    \"single_parent_children_6_to_17_years\", \"singles\"]\n",
    "\n",
    "    grouped_df = combined_df.groupby([grouping_element], as_index=False)[\n",
    "        list_columns].sum()\n",
    "    grouped_df[\"tot_pop_count\"] = grouped_df.iloc[:, 1:].sum(axis=1)\n",
    "\n",
    "    grouped_df[\"%_dist_of_couple_children_0_to_5_years\"] = grouped_df[\"couple_children_0_to_5_years\"] / \\\n",
    "        grouped_df[\"tot_pop_count\"]\n",
    "    grouped_df[\"%_dist_of_couple_children_18_or_above\"] = grouped_df[\"couple_children_18_or_above\"] / \\\n",
    "        grouped_df[\"tot_pop_count\"]\n",
    "    grouped_df[\"%_dist_of_couple_children_6_to_17_years\"] = grouped_df[\"couple_children_6_to_17_years\"] / \\\n",
    "        grouped_df[\"tot_pop_count\"]\n",
    "    grouped_df[\"%_dist_of_couple_without_children\"] = grouped_df[\"couple_without_children\"] / \\\n",
    "        grouped_df[\"tot_pop_count\"]\n",
    "    grouped_df[\"%_dist_of_single_parent_children_0_to_5_years\"] = grouped_df[\"single_parent_children_0_to_5_years\"] / \\\n",
    "        grouped_df[\"tot_pop_count\"]\n",
    "    grouped_df[\"%_dist_of_single_parent_children_18_or_above\"] = grouped_df[\"single_parent_children_18_or_above\"] / \\\n",
    "        grouped_df[\"tot_pop_count\"]\n",
    "    grouped_df[\"%_dist_of_single_parent_children_6_to_17_years\"] = grouped_df[\"single_parent_children_6_to_17_years\"] / \\\n",
    "        grouped_df[\"tot_pop_count\"]\n",
    "    grouped_df[\"%_dist_of_singles\"] = grouped_df[\"singles\"] / \\\n",
    "        grouped_df[\"tot_pop_count\"]\n",
    "\n",
    "    returned_df = grouped_df.drop([\"tot_pop_count\"], axis=1)\n",
    "    return returned_df\n",
    "\n",
    "\n",
    "# Simens functions\n",
    "def average_revenue_of_chain(dataset_stores):\n",
    "    \"Average revenue of chains in datasett\"\n",
    "    dataset_stores = dataset_stores[(dataset_stores[\"year\"] == 2016)]\n",
    "    return dataset_stores.groupby(['chain_name'])['revenue'].mean()\n",
    "\n",
    "\n",
    "def average_revenue_of_mall(dataset_stores):\n",
    "    \"Average revenue of malls in dataset\"\n",
    "    dataset_stores = dataset_stores[(dataset_stores[\"year\"] == 2016)]\n",
    "    return dataset_stores.groupby(['mall_name'])['revenue'].mean()\n",
    "\n",
    "\n",
    "def mean_income_per_capita(dataset_age, dataset_income):\n",
    "    \"mean income per capita per grunnkrets\"\n",
    "    age_df = population(dataset_age)\n",
    "    income_df = dataset_income[dataset_income[\"year\"] == 2016]\n",
    "    age_and_income_df = age_df.merge(income_df, how='left', on='grunnkrets_id')\n",
    "    mean_income = age_and_income_df.drop(['year', 'singles', 'couple_without_children',\n",
    "                                         'couple_with_children', 'other_households', 'single_parent_with_children'], axis=1)\n",
    "    mean_income['mean_income'] = mean_income['all_households'] / \\\n",
    "        mean_income['population_count']\n",
    "    mean_income = mean_income.drop(['all_households'], axis=1)\n",
    "\n",
    "    return mean_income\n",
    "\n",
    "\n",
    "def mean_income_per_capita_grouped(dataset_age, dataset_income, dataset_geography, grouping_element):\n",
    "    # gets data from mean_income_per_capita functino\n",
    "    data_mean_income = mean_income_per_capita(dataset_age, dataset_income)\n",
    "    # gets data from geography set and makes sure we only use data for 2016\n",
    "    geography_df = dataset_geography[dataset_geography[\"year\"] == 2016]\n",
    "    # gets the data of mean income with the geography data\n",
    "    mean_income_geo_df = data_mean_income.merge(\n",
    "        geography_df, how='left', on='grunnkrets_id')\n",
    "    # sum the number of people based on grouping element\n",
    "    grouped_population_df = mean_income_geo_df.groupby(\n",
    "        [grouping_element], as_index=False)[\"population_count\"].sum()\n",
    "    # merge this with the grunnkrets to see both total population per selected area and grunnkrets\n",
    "    total_grouped_df = mean_income_geo_df.merge(\n",
    "        grouped_population_df, how='left', on=grouping_element)\n",
    "    portion_income_df = total_grouped_df\n",
    "    # find ration of grunnkrets to total population and multiply this with grunnkrets mean income\n",
    "    portion_income_df['mean_income'] = total_grouped_df['mean_income'] * \\\n",
    "        total_grouped_df['population_count_x'] / \\\n",
    "        total_grouped_df['population_count_y']\n",
    "    # add these incomes together, should add up to the total mean income for the selected area\n",
    "    grouped_income_df = portion_income_df.groupby(\n",
    "        [grouping_element], as_index=False)[\"mean_income\"].sum()\n",
    "    return grouped_income_df\n",
    "\n",
    "# def stores_density_per_location_by_type(stores_df, plaace_df, grunnkrets_df, geo=\"district_name\", lv_desc=\"lv1_desc\"):\n",
    "#     \"\"\"\n",
    "#     Density of stores of the same type in a geographic location.\n",
    "\n",
    "#     This depends on population\n",
    "#     \"\"\"\n",
    "#     number_of_stores = store_types_count_by_geo_group(\n",
    "#         stores_df, plaace_df, grunnkrets_df, geo=geo, lv_desc=lv_desc)['count']\n",
    "#     population = 0\n",
    "#     return number_of_stores / population\n",
    "\n",
    "def stores_in_radius(stores_df, plaace_df, radius=0.1, store_type_group=None):\n",
    "    \"\"\"\n",
    "    Number of stores within a given radius. Can also indicate category to filter.\n",
    "    \"\"\"\n",
    "    mat = cdist(stores_df[['lat', 'lon']],\n",
    "                stores_df[['lat', 'lon']], metric='euclidean')\n",
    "    new_df = pd.DataFrame(\n",
    "        mat, index=stores_df['store_id'], columns=stores_df['store_id'])\n",
    "\n",
    "    if store_type_group is None:\n",
    "        count = new_df[(new_df < radius) & (new_df > 0)].count(axis=1)\n",
    "        return count.to_frame(name=\"count\")\n",
    "\n",
    "    else:\n",
    "        combined_df = stores_df.merge(\n",
    "            plaace_df, how=\"inner\", on=\"plaace_hierarchy_id\")\n",
    "        test_df = new_df[(new_df < radius) & (new_df > 0)]\n",
    "        store_count = {}\n",
    "\n",
    "        for index, row in test_df.iterrows():\n",
    "            nearby_stores = row.dropna().index.values\n",
    "            index_type = combined_df[combined_df['store_id']\n",
    "                                     == index][store_type_group].values[0]\n",
    "            number_same = combined_df[(combined_df['store_id'].isin(nearby_stores)) & (\n",
    "                combined_df[store_type_group] == index_type)]['store_id'].count()\n",
    "            store_count[index] = number_same\n",
    "\n",
    "        df = pd.DataFrame.from_dict(store_count, orient='index', columns=['count'])\n",
    "        df.index.rename('store_id', inplace=True)\n",
    "        return df\n",
    "\n",
    "def store_types_count_by_geo_group(stores_df, plaace_df, grunnkrets_df, impuded_df, agg_name, geo_group=\"district_name\", store_type_group=\"lv1_desc\"):\n",
    "    \"\"\"\n",
    "    Number of stores of the same type in a geographic location.\n",
    "    \"\"\"\n",
    "    #combined_df = stores_df.merge(plaace_df, how=\"inner\", on=\"plaace_hierarchy_id\").merge(grunnkrets_df, how=\"inner\", on=\"grunnkrets_id\")\n",
    "    combined_df = impuded_df.merge(plaace_df, how =\"left\", on =\"plaace_hierarchy_id\")\n",
    "    return combined_df.groupby(by=[geo_group, store_type_group])['store_id'].count().reset_index(name=agg_name)\n",
    "\n",
    "\n",
    "def store_types_revenue_by_geo_group(stores_df, plaace_df, grunnkrets_df, agg_name, geo_group=\"district_name\", store_type_group=\"lv1_desc\"):\n",
    "    \"\"\"\n",
    "    Total revenue of stores of the same type in a geographic location.\n",
    "    \"\"\"\n",
    "    combined_df = stores_df.merge(plaace_df, how=\"inner\", on=\"plaace_hierarchy_id\").merge(\n",
    "        grunnkrets_df, how=\"inner\", on=\"grunnkrets_id\")\n",
    "    return combined_df.groupby(by=[geo_group, store_type_group])['revenue'].sum().reset_index(name=agg_name)\n",
    "\n",
    "def store_types_all_count_by_geo_groups(stores_df, plaace_df, grunnkrets_df, impuded_df, store_types, geo_groups):\n",
    "    #merged_df = stores_df.merge(grunnkrets_df, how=\"left\", on=\"grunnkrets_id\").merge(plaace_df, how=\"left\", on=\"plaace_hierarchy_id\")\n",
    "    merged_df = impuded_df.merge(plaace_df, how = \"left\", on = \"plaace_hierarchy_id\")\n",
    "    df_list = []\n",
    "    for geo_group in geo_groups:\n",
    "        for store_type in store_types:\n",
    "            df = store_types_count_by_geo_group(stores_df, plaace_df, grunnkrets_df, impuded_df, geo_group=geo_group, agg_name=f\"{geo_group}_{store_type}\", store_type_group=store_type)\n",
    "            df_list.append(merged_df.merge(df, how=\"left\", on=[geo_group, store_type])[['store_id', f\"{geo_group}_{store_type}\"]])\n",
    "    \n",
    "    dfs = [df.set_index('store_id') for df in df_list]\n",
    "    return pd.concat(dfs, axis=1)\n",
    "\n",
    "def store_types_all_revenue_by_geo_groups(stores_df, plaace_df, grunnkrets_df, store_types, geo_groups):\n",
    "    merged_df = stores_df.merge(grunnkrets_df, how=\"left\", on=\"grunnkrets_id\").merge(plaace_df, how=\"left\", on=\"plaace_hierarchy_id\")\n",
    "    \n",
    "    df_list = []\n",
    "    for geo_group in geo_groups:\n",
    "        for store_type in store_types:\n",
    "            df = store_types_revenue_by_geo_group(stores_df, plaace_df, grunnkrets_df, geo_group=geo_group, agg_name=f\"{geo_group}_{store_type}\", store_type_group=store_type)\n",
    "            df_list.append(merged_df.merge(df, how=\"left\", on=[geo_group, store_type])[['store_id', f\"{geo_group}_{store_type}\"]])\n",
    "    \n",
    "    dfs = [df.set_index('store_id') for df in df_list]\n",
    "    return pd.concat(dfs, axis=1)\n",
    "    \n",
    "def stores_in_radius_by_type(stores_df, plaace_df, store_types, radius=0.1):\n",
    "    df_list = []\n",
    "    df_list.append(stores_in_radius(stores_df, plaace_df, radius=radius).rename(columns={'count':'number_of_all_stores'})) # All stores in radius\n",
    "    \n",
    "    for store_type in store_types:\n",
    "        df = stores_in_radius(stores_df, plaace_df, store_type_group=store_type, radius=radius)\n",
    "        df.rename(columns={'count': f'number_of_{store_type}'}, inplace=True)\n",
    "        df_list.append(df)\n",
    "    \n",
    "    return pd.concat(df_list, axis=1)\n",
    "\n",
    "def bus_stops_lat_lon(bus_stops_df):\n",
    "    \"\"\"\n",
    "    Extract latitude and longitude as separate columns.\n",
    "    \"\"\"\n",
    "    bus_stops_df['lng_lat'] = bus_stops_df['geometry'].str.extract(\n",
    "        r'\\((.*?)\\)')\n",
    "    bus_stops_df[['lon', 'lat']] = bus_stops_df['lng_lat'].str.split(\n",
    "        \" \", 1, expand=True)\n",
    "    bus_stops_df[['lon', 'lat']] = bus_stops_df[[\n",
    "        'lon', 'lat']].apply(pd.to_numeric)\n",
    "    return bus_stops_df[['busstop_id', 'stopplace_type', 'importance_level', 'side_placement', 'geometry', 'lat', 'lon']]\n",
    "\n",
    "def bus_stops_closest(stores_df, bus_stops_df, importance_level=\"Regionalt knutepunkt\"):\n",
    "    \"\"\"\n",
    "    Id and distance of the closest bus stop to all stores.\n",
    "    \"\"\"\n",
    "    bus_stops_df = bus_stops_df[bus_stops_df['importance_level'] == importance_level]\n",
    "    mat = cdist(stores_df[['lat', 'lon']],\n",
    "                bus_stops_df[['lat', 'lon']], metric='euclidean')\n",
    "\n",
    "    new_df = pd.DataFrame(\n",
    "        mat, index=stores_df['store_id'], columns=bus_stops_df['busstop_id'])\n",
    "\n",
    "    stores = stores_df.store_id\n",
    "    closest = new_df.idxmin(axis=1)\n",
    "    distance = new_df.min(axis=1)\n",
    "\n",
    "    return pd.DataFrame({'store_id': stores.values, 'closest_bus_stop': closest.values, 'distance': distance.values})\n",
    "\n",
    "def bus_stops_in_radius(stores_df, bus_stops_df, radius=0.1, importance_level=None):\n",
    "    \"\"\"\n",
    "    Number of bus stops within a given radius. The importance level of bus stops can be specified.\n",
    "    \"\"\"\n",
    "    if importance_level is not None:\n",
    "        bus_stops_df = bus_stops_df[bus_stops_df['importance_level'] == importance_level]\n",
    "\n",
    "    mat = cdist(stores_df[['lat', 'lon']],\n",
    "                bus_stops_df[['lat', 'lon']], metric='euclidean')\n",
    "    new_df = pd.DataFrame(\n",
    "        mat, index=stores_df['store_id'], columns=bus_stops_df['busstop_id'])\n",
    "    count = pd.DataFrame(new_df[new_df < radius].count(axis=1)).reset_index()\n",
    "    count.rename(columns={0: 'count'}, inplace=True)\n",
    "    return count\n",
    "\n",
    "# Relevant feature engineering functions.\n",
    "def bus_stops_distance_by_importance(stores_df, bus_stops_df, stop_importance_levels):\n",
    "    \"\"\"\n",
    "    Distance for each store to the closest bus stop of each importance_level\n",
    "    \"\"\"\n",
    "    df_list = []\n",
    "    for importance_level in stop_importance_levels:\n",
    "        importance_level_cleaned = importance_level.lower().replace(\" \", \"_\")\n",
    "        df = bus_stops_closest(stores_df, bus_stops_df, importance_level=importance_level)\n",
    "        df.rename(columns={'distance': f'distance_to_{importance_level_cleaned}'}, inplace=True)\n",
    "        df_list.append(df[['store_id', f'distance_to_{importance_level_cleaned}']])\n",
    "\n",
    "    dfs = [df.set_index('store_id') for df in df_list]\n",
    "    return pd.concat(dfs, axis=1)\n",
    "\n",
    "def bus_stops_in_radius_by_importance(stores_df, bus_stops_df, stop_importance_levels, radius=0.01):\n",
    "    \"\"\"\n",
    "    Number of bus stops in radius of store for each importance level.\n",
    "    \"\"\"\n",
    "    df_list = []\n",
    "    df_list.append(bus_stops_in_radius(stores_df, bus_stops_df, radius=radius).rename(columns={'count':'number_of_all_stop_types'})) # All bus stops in radius\n",
    "    \n",
    "    for importance_level in stop_importance_levels:\n",
    "        importance_level_cleaned = importance_level.lower().replace(\" \", \"_\")\n",
    "        df = bus_stops_in_radius(stores_df, bus_stops_df, importance_level=importance_level, radius=radius)\n",
    "        df.rename(columns={'count': f'number_of_{importance_level_cleaned}'}, inplace=True)\n",
    "        df_list.append(df[['store_id', f'number_of_{importance_level_cleaned}']])\n",
    "\n",
    "    dfs = [df.set_index('store_id') for df in df_list]\n",
    "    return pd.concat(dfs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-647-f5e38141272d>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  age_df[\"population_count\"] = population\n",
      "<ipython-input-647-f5e38141272d>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  age_df[\"population_count\"] = population\n",
      "<ipython-input-647-f5e38141272d>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  age_df[\"population_count\"] = population\n",
      "<ipython-input-647-f5e38141272d>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  age_df[\"population_count\"] = population\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "grunnkrets_id_lv1_desc    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 665,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = store_types_all_count_by_geo_groups(stores_train, plaace_hierarchy, grunnkrets_norway, stores_gk_impuded, geo_groups=[\"grunnkrets_id\"], store_types=[\"lv1_desc\"])\n",
    "df1 = population_per_store_types(stores_train, plaace_hierarchy, grunnkrets_norway, grunnkrets_age, stores_gk_impuded, agg_name =\"stores_count\", geo_group=\"grunnkrets_id\", store_type_group=\"lv1_desc\")\n",
    "df2 = population_grouped(grunnkrets_age, grunnkrets_norway, grouping_element=\"grunnkrets_id\")\n",
    "df3 = store_types_count_by_geo_group(stores_train, plaace_hierarchy, grunnkrets_norway, stores_gk_impuded, agg_name=\"stores_count\", geo_group=\"grunnkrets_id\", store_type_group=\"lv1_desc\")\n",
    "df4 = age_distrubution(grunnkrets_age, grunnkrets_norway, stores_age_impuded, grouping_element=\"grunnkrets_name\")\n",
    "df5 = household_type_distrubution(grunnkrets_norway, grunnkrets_household, grouping_element=\"grunnkrets_name\")\n",
    "\n",
    "geo = grunnkrets_norway[grunnkrets_norway[\"year\"]==2016]\n",
    "house = grunnkrets_household[grunnkrets_household[\"year\"]==2016]\n",
    "age = grunnkrets_age[grunnkrets_age[\"year\"] == 2016]\n",
    "\n",
    "merged = geo.merge(house, how =\"inner\", on =\"grunnkrets_id\")\n",
    "merged2 = age.merge(geo, how =\"left\", on =\"grunnkrets_id\")\n",
    "merged3 = stores_train.merge(age, how =\"left\", on =\"grunnkrets_id\")\n",
    "\n",
    "\n",
    "dist = household_type_distrubution(grunnkrets_norway, grunnkrets_household, grouping_element=\"grunnkrets_id\")\n",
    "dist.isna().sum()\n",
    "#stores_train.isna().sum() \n",
    "#testing = please[please[\"store_id\"] == \"979617615-979639317-58196\"]\n",
    "\n",
    "dist[dist[\"%_dist_of_couple_children_0_to_5_years\"].isna()]\n",
    "house[house[\"grunnkrets_id\"] == 1062008\t]\n",
    "\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New functions based on the previus feature_functions that returns store_id as index with all different geo_groups (possibly store_types when appropriate) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-678-426c037f1c9a>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  age_df[\"population_count\"] = population\n",
      "<ipython-input-678-426c037f1c9a>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  age_df[\"population_count\"] = population\n",
      "<ipython-input-678-426c037f1c9a>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  age_df[\"population_count\"] = population\n",
      "<ipython-input-678-426c037f1c9a>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  age_df[\"population_count\"] = population\n",
      "<ipython-input-678-426c037f1c9a>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  age_df[\"population_count\"] = population\n",
      "<ipython-input-678-426c037f1c9a>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  age_df[\"population_count\"] = population\n",
      "<ipython-input-678-426c037f1c9a>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  age_df[\"population_count\"] = population\n",
      "<ipython-input-678-426c037f1c9a>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  age_df[\"population_count\"] = population\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "grunnkrets_id_num_kids              821\n",
       "grunnkrets_id_num_kids+             821\n",
       "grunnkrets_id_num_youths            821\n",
       "grunnkrets_id_num_youthAdult        821\n",
       "grunnkrets_id_num_adult             821\n",
       "grunnkrets_id_num_adults+           821\n",
       "grunnkrets_id_num_pensinors         821\n",
       "grunnkrets_id_kids_%                821\n",
       "grunnkrets_id_kids+_%               821\n",
       "grunnkrets_id_youths_%              821\n",
       "grunnkrets_id_youthAdult_%          821\n",
       "grunnkrets_id_adult_%               821\n",
       "grunnkrets_id_adults+_%             821\n",
       "grunnkrets_id_pensinors_%           821\n",
       "grunnkrets_name_num_kids            685\n",
       "grunnkrets_name_num_kids+           685\n",
       "grunnkrets_name_num_youths          685\n",
       "grunnkrets_name_num_youthAdult      685\n",
       "grunnkrets_name_num_adult           685\n",
       "grunnkrets_name_num_adults+         685\n",
       "grunnkrets_name_num_pensinors       685\n",
       "grunnkrets_name_kids_%              685\n",
       "grunnkrets_name_kids+_%             685\n",
       "grunnkrets_name_youths_%            685\n",
       "grunnkrets_name_youthAdult_%        685\n",
       "grunnkrets_name_adult_%             685\n",
       "grunnkrets_name_adults+_%           685\n",
       "grunnkrets_name_pensinors_%         685\n",
       "district_name_num_kids                2\n",
       "district_name_num_kids+               2\n",
       "district_name_num_youths              2\n",
       "district_name_num_youthAdult          2\n",
       "district_name_num_adult               2\n",
       "district_name_num_adults+             2\n",
       "district_name_num_pensinors           2\n",
       "district_name_kids_%                  2\n",
       "district_name_kids+_%                 2\n",
       "district_name_youths_%                2\n",
       "district_name_youthAdult_%            2\n",
       "district_name_adult_%                 2\n",
       "district_name_adults+_%               2\n",
       "district_name_pensinors_%             2\n",
       "municipality_name_num_kids            0\n",
       "municipality_name_num_kids+           0\n",
       "municipality_name_num_youths          0\n",
       "municipality_name_num_youthAdult      0\n",
       "municipality_name_num_adult           0\n",
       "municipality_name_num_adults+         0\n",
       "municipality_name_num_pensinors       0\n",
       "municipality_name_kids_%              0\n",
       "municipality_name_kids+_%             0\n",
       "municipality_name_youths_%            0\n",
       "municipality_name_youthAdult_%        0\n",
       "municipality_name_adult_%             0\n",
       "municipality_name_adults+_%           0\n",
       "municipality_name_pensinors_%         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 679,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def age_dist_by_geo_group(impuded_gk_df, age_df, grunnkrets_df): \n",
    "    grunnkrets_df_2016 = grunnkrets_df[grunnkrets_df[\"year\"] == 2016]  \n",
    "    #combined_df = stores_df.merge(grunnkrets_df_2016, how = \"left\", on = \"grunnkrets_id\")\n",
    "    combined_df = impuded_gk_df\n",
    "    \n",
    "\n",
    "    age_columns = ['num_kids', 'num_kids+', 'num_youths', 'num_youthAdult', 'num_adult',\n",
    "       'num_adults+', 'num_pensinors', 'kids_%', 'kids+_%', 'youths_%',\n",
    "       'youthAdult_%', 'adult_%', 'adults+_%', 'pensinors_%']\n",
    "    \n",
    "    df_list = []\n",
    "    geo_groups = [\"grunnkrets_id\", \"grunnkrets_name\", \"district_name\", \"municipality_name\"]\n",
    "    for geo_group in geo_groups: \n",
    "      age_dist_df = age_distrubution(age_df, grunnkrets_df, geo_group)\n",
    "      merged_df = combined_df.merge(age_dist_df, how = \"left\", on = geo_group)[[\"store_id\"] + age_columns]\n",
    "      merged_df.set_index(\"store_id\", inplace = True)\n",
    "      merged_df2 = merged_df.add_prefix(f'{geo_group}_')\n",
    "      df_list.append(merged_df2)\n",
    "    \n",
    "    return pd.concat(df_list, axis = 1)\n",
    "    \n",
    "df = age_dist_by_geo_group(stores_gk_impuded, grunnkrets_age, grunnkrets_norway)\n",
    "df.isna().sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "grunnkrets_id_couple_children_0_to_5_years                          153\n",
       "grunnkrets_id_couple_children_18_or_above                           153\n",
       "grunnkrets_id_couple_children_6_to_17_years                         153\n",
       "grunnkrets_id_couple_without_children                               153\n",
       "grunnkrets_id_single_parent_children_0_to_5_years                   153\n",
       "                                                                   ... \n",
       "municipality_name_%_dist_of_couple_without_children                   0\n",
       "municipality_name_%_dist_of_single_parent_children_0_to_5_years       0\n",
       "municipality_name_%_dist_of_single_parent_children_18_or_above        0\n",
       "municipality_name_%_dist_of_single_parent_children_6_to_17_years      0\n",
       "municipality_name_%_dist_of_singles                                   0\n",
       "Length: 64, dtype: int64"
      ]
     },
     "execution_count": 671,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def household_dist_by_geo_group(household_df, grunnkrets_df, impuded_df):\n",
    "    grunnkrets_df_2016 = grunnkrets_df[grunnkrets_df[\"year\"] == 2016]  \n",
    "    #combined_df = stores_df.merge(grunnkrets_df_2016, how = \"left\", on = \"grunnkrets_id\")\n",
    "    combined_df = impuded_df\n",
    "    household_colmns = ['couple_children_0_to_5_years', 'couple_children_18_or_above', 'couple_children_6_to_17_years', 'couple_without_children',\n",
    "       'single_parent_children_0_to_5_years','single_parent_children_18_or_above','single_parent_children_6_to_17_years', 'singles',\n",
    "       '%_dist_of_couple_children_0_to_5_years','%_dist_of_couple_children_18_or_above','%_dist_of_couple_children_6_to_17_years',\n",
    "       '%_dist_of_couple_without_children','%_dist_of_single_parent_children_0_to_5_years','%_dist_of_single_parent_children_18_or_above',\n",
    "       '%_dist_of_single_parent_children_6_to_17_years', '%_dist_of_singles']\n",
    "       \n",
    "    df_list = []\n",
    "    geo_groups = [\"grunnkrets_id\", \"grunnkrets_name\", \"district_name\", \"municipality_name\"]\n",
    "\n",
    "    for geo_group in geo_groups: \n",
    "        household_type_df = household_type_distrubution(grunnkrets_df_2016, household_df, geo_group)\n",
    "        merged_df = combined_df.merge(household_type_df, how = \"left\", on = geo_group)[[\"store_id\"] + household_colmns]\n",
    "        merged_df.set_index(\"store_id\", inplace = True)\n",
    "        merged_df2 = merged_df.add_prefix(f'{geo_group}_')\n",
    "        df_list.append(merged_df2)\n",
    "    return pd.concat(df_list, axis = 1)\n",
    "\n",
    "df = household_dist_by_geo_group(grunnkrets_household, grunnkrets_norway, stores_gk_impuded)\n",
    "df.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-647-f5e38141272d>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  age_df[\"population_count\"] = population\n",
      "<ipython-input-647-f5e38141272d>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  age_df[\"population_count\"] = population\n",
      "<ipython-input-647-f5e38141272d>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  age_df[\"population_count\"] = population\n",
      "<ipython-input-647-f5e38141272d>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  age_df[\"population_count\"] = population\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "grunnkrets_id_population_count        821\n",
       "grunnkrets_name_population_count      685\n",
       "district_name_population_count          2\n",
       "municipality_name_population_count      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 670,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def population_count_grouped_by_geo_group(age_df, grunnkrets_df, impuded_df): \n",
    "     grunnkrets_df_2016 = grunnkrets_df[grunnkrets_df[\"year\"] == 2016]  \n",
    "     #combined_df = stores_df.merge(grunnkrets_df_2016, how = \"left\", on = \"grunnkrets_id\")\n",
    "     combined_df = impuded_df\n",
    "\n",
    "     population_columns = [\"population_count\"]\n",
    "     df_list = []\n",
    "     geo_groups = [\"grunnkrets_id\", \"grunnkrets_name\", \"district_name\", \"municipality_name\"]\n",
    "\n",
    "     for geo_group in geo_groups: \n",
    "          pop_df = population_grouped(age_df, grunnkrets_df, geo_group)\n",
    "          merged_df = combined_df.merge(pop_df, how = \"left\", on = geo_group)[[\"store_id\"] + population_columns]\n",
    "          merged_df.set_index(\"store_id\", inplace = True)\n",
    "          merged_df2 = merged_df.add_prefix(f'{geo_group}_')\n",
    "          df_list.append(merged_df2)\n",
    "\n",
    "     return pd.concat(df_list, axis = 1)\n",
    "\n",
    "df = population_count_grouped_by_geo_group(grunnkrets_age, grunnkrets_norway, stores_gk_impuded)\n",
    "df.isna().sum()\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-647-f5e38141272d>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  age_df[\"population_count\"] = population\n",
      "<ipython-input-647-f5e38141272d>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  age_df[\"population_count\"] = population\n",
      "<ipython-input-647-f5e38141272d>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  age_df[\"population_count\"] = population\n",
      "<ipython-input-647-f5e38141272d>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  age_df[\"population_count\"] = population\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "grunnkrets_id_density        821\n",
       "grunnkrets_name_density      685\n",
       "district_name_density          2\n",
       "municipality_name_density      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 673,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def population_density_grouped_by_geo_group(age_df, grunnkrets_df, impuded_df ):\n",
    "    grunnkrets_df_2016 = grunnkrets_df[grunnkrets_df[\"year\"] == 2016]  \n",
    "    #combined_df = stores_df.merge(grunnkrets_df_2016, how = \"left\", on = \"grunnkrets_id\")\n",
    "    combined_df = impuded_df\n",
    "\n",
    "    pop_density_columns = [\"density\"]\n",
    "    df_list = []\n",
    "    geo_groups = [\"grunnkrets_id\", \"grunnkrets_name\", \"district_name\", \"municipality_name\"]\n",
    "\n",
    "    for geo_group in geo_groups: \n",
    "        pop_df = population_density(age_df, grunnkrets_df, geo_group)\n",
    "        merged_df = combined_df.merge(pop_df, how = \"left\", on = geo_group)[[\"store_id\"] + pop_density_columns]\n",
    "        merged_df.set_index(\"store_id\", inplace = True)\n",
    "        merged_df2 = merged_df.add_prefix(f'{geo_group}_')\n",
    "        df_list.append(merged_df2)\n",
    "\n",
    "    return pd.concat(df_list, axis = 1)\n",
    "\n",
    "df = population_density_grouped_by_geo_group(grunnkrets_age, grunnkrets_norway, stores_gk_impuded)\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-647-f5e38141272d>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  age_df[\"population_count\"] = population\n",
      "<ipython-input-647-f5e38141272d>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  age_df[\"population_count\"] = population\n",
      "<ipython-input-647-f5e38141272d>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  age_df[\"population_count\"] = population\n",
      "<ipython-input-647-f5e38141272d>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  age_df[\"population_count\"] = population\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "grunnkrets_id_lv1_desc_pop_per_num_store        821\n",
       "grunnkrets_id_lv2_desc_pop_per_num_store        821\n",
       "grunnkrets_id_lv3_desc_pop_per_num_store        821\n",
       "grunnkrets_id_lv4_desc_pop_per_num_store        821\n",
       "district_name_lv1_desc_pop_per_num_store          2\n",
       "district_name_lv2_desc_pop_per_num_store          2\n",
       "district_name_lv3_desc_pop_per_num_store          2\n",
       "district_name_lv4_desc_pop_per_num_store          2\n",
       "municipality_name_lv1_desc_pop_per_num_store      0\n",
       "municipality_name_lv2_desc_pop_per_num_store      0\n",
       "municipality_name_lv3_desc_pop_per_num_store      0\n",
       "municipality_name_lv4_desc_pop_per_num_store      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 675,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def population_per_store_type_grouped_by_geo_groups(stores_df, plaace_df, grunnkrets_df, age_df, impuded_df, geo_groups, store_types, agg_string):\n",
    "    grunnkrets_df_2016 = grunnkrets_df[grunnkrets_df[\"year\"] == 2016]\n",
    "    num_stores_type_by_geo_group = store_types_all_count_by_geo_groups(stores_df, plaace_df, grunnkrets_df_2016, impuded_df, store_types=store_types, geo_groups=geo_groups)\n",
    "    pop_count_by_geo_group = population_count_grouped_by_geo_group(age_df, grunnkrets_df_2016, impuded_df)\n",
    "    combined_df = num_stores_type_by_geo_group.merge(pop_count_by_geo_group, how =\"left\", on = \"store_id\")\n",
    "\n",
    "    for geo_group in geo_groups: \n",
    "        for store_type in store_types: \n",
    "            combined_df[f'{geo_group}_{store_type}_' + agg_string] = combined_df[f'{geo_group}_population_count'] /combined_df[f'{geo_group}_{store_type}']\n",
    "\n",
    "    return combined_df.loc[:, (f'{geo_groups[0]}_{store_types[0]}_' + agg_string) : ]\n",
    "\n",
    "store =[\"lv1_desc\", \"lv2_desc\", \"lv3_desc\", \"lv4_desc\"]\n",
    "geo= [\"grunnkrets_id\",\"district_name\", \"municipality_name\"]\n",
    "\n",
    "df = population_per_store_type_grouped_by_geo_groups(stores_train, plaace_hierarchy, grunnkrets_norway, grunnkrets_age, stores_gk_impuded, geo_groups=geo, store_types=store, agg_string=\"pop_per_num_store\") \n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_mall_only(stores_df): \n",
    "    df = is_mall(stores_df).drop([\"mall_name\"], axis = 1)\n",
    "    df.set_index(\"store_id\", inplace=True)\n",
    "    return df\n",
    "\n",
    "#is_mall_only(stores_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_chain_only(stores_df): \n",
    "    df = is_chain(stores_df).drop([\"chain_name\"], axis = 1)\n",
    "    df.set_index(\"store_id\", inplace=True)\n",
    "    return df\n",
    "\n",
    "#is_chain_only(stores_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mean_revenue_chain                9122\n",
       "mean_revenue_mall                10579\n",
       "mean_income_grunnkrets_id          821\n",
       "mean_income_district_name           32\n",
       "mean_income_municipality_name       30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 676,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = simens_df.set_index(\"store_id\")\n",
    "income_df= df.drop([\"Unnamed: 0\"], axis = 1)\n",
    "income_df \n",
    "\n",
    "id_and_revenue_df= stores_train[[\"store_id\", \"revenue\"]]\n",
    "id_and_revenue_df\n",
    "\n",
    "income_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging of features into one dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 6.55 GiB for an array with shape (12859, 68395) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-76-07b5e256543f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mbus_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbus_stops_lat_lon\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbusstops\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mbusstop_radius\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbus_stops_in_radius_by_importance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstores_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbusstops\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstop_importance_levels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimportance_levels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mradius\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mpop_count_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpopulation_count_grouped_by_geo_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstores_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrunnkrets_age\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrunnkrets_norway\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-46-cca77c40b31c>\u001b[0m in \u001b[0;36mbus_stops_in_radius_by_importance\u001b[1;34m(stores_df, bus_stops_df, stop_importance_levels, radius)\u001b[0m\n\u001b[0;32m    376\u001b[0m     \"\"\"\n\u001b[0;32m    377\u001b[0m     \u001b[0mdf_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 378\u001b[1;33m     \u001b[0mdf_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbus_stops_in_radius\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstores_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbus_stops_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mradius\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mradius\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'count'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'number_of_all_stop_types'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# All bus stops in radius\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    379\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    380\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mimportance_level\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstop_importance_levels\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-46-cca77c40b31c>\u001b[0m in \u001b[0;36mbus_stops_in_radius\u001b[1;34m(stores_df, bus_stops_df, radius, importance_level)\u001b[0m\n\u001b[0;32m    352\u001b[0m     new_df = pd.DataFrame(\n\u001b[0;32m    353\u001b[0m         mat, index=stores_df['store_id'], columns=bus_stops_df['busstop_id'])\n\u001b[1;32m--> 354\u001b[1;33m     \u001b[0mcount\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_df\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mradius\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    355\u001b[0m     \u001b[0mcount\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'count'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\aminp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3009\u001b[0m         \u001b[1;31m# Do we have a (boolean) DataFrame?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3010\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3011\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3012\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3013\u001b[0m         \u001b[1;31m# Do we have a (boolean) 1d indexer?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\aminp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mwhere\u001b[1;34m(self, cond, other, inplace, axis, level, errors, try_cast)\u001b[0m\n\u001b[0;32m   9284\u001b[0m         \"\"\"\n\u001b[0;32m   9285\u001b[0m         \u001b[0mother\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 9286\u001b[1;33m         return self._where(\n\u001b[0m\u001b[0;32m   9287\u001b[0m             \u001b[0mcond\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtry_cast\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtry_cast\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   9288\u001b[0m         )\n",
      "\u001b[1;32mc:\\Users\\aminp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_where\u001b[1;34m(self, cond, other, inplace, axis, level, errors, try_cast)\u001b[0m\n\u001b[0;32m   9134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   9135\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 9136\u001b[1;33m             new_data = self._mgr.where(\n\u001b[0m\u001b[0;32m   9137\u001b[0m                 \u001b[0mother\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   9138\u001b[0m                 \u001b[0mcond\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcond\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\aminp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mwhere\u001b[1;34m(self, other, cond, align, errors, try_cast, axis)\u001b[0m\n\u001b[0;32m    555\u001b[0m             \u001b[0mother\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextract_numpy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    556\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 557\u001b[1;33m         return self.apply(\n\u001b[0m\u001b[0;32m    558\u001b[0m             \u001b[1;34m\"where\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m             \u001b[0malign_keys\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malign_keys\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\aminp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, f, align_keys, ignore_failures, **kwargs)\u001b[0m\n\u001b[0;32m    425\u001b[0m                     \u001b[0mapplied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 427\u001b[1;33m                     \u001b[0mapplied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    428\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mignore_failures\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\aminp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36mwhere\u001b[1;34m(self, other, cond, errors, try_cast, axis)\u001b[0m\n\u001b[0;32m   1501\u001b[0m             \u001b[1;31m# By the time we get here, we should have all Series/Index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1502\u001b[0m             \u001b[1;31m#  args extracted to ndarray\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1503\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexpressions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcond\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1504\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1505\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_na\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\aminp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\computation\\expressions.py\u001b[0m in \u001b[0;36mwhere\u001b[1;34m(cond, a, b, use_numexpr)\u001b[0m\n\u001b[0;32m    250\u001b[0m     \"\"\"\n\u001b[0;32m    251\u001b[0m     \u001b[1;32massert\u001b[0m \u001b[0m_where\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_where\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcond\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0muse_numexpr\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0m_where_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcond\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\aminp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\computation\\expressions.py\u001b[0m in \u001b[0;36m_where_standard\u001b[1;34m(cond, a, b)\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_where_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcond\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m     \u001b[1;31m# Caller is responsible for extracting ndarray if necessary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 162\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcond\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mwhere\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 6.55 GiB for an array with shape (12859, 68395) and data type float64"
     ]
    }
   ],
   "source": [
    "store =[\"lv1_desc\", \"lv2_desc\", \"lv3_desc\", \"lv4_desc\"]\n",
    "geo= [\"grunnkrets_id\", \"district_name\", \"municipality_name\"]\n",
    "importance_levels = [\"Mangler viktighetsnivå\", \"Standard holdeplass\", \"Lokalt knutepunkt\",\"Regionalt knutepunkt\", \"Annen viktig holdeplass\", \"Nasjonalt knutepunkt\"]\n",
    "grunnkrets_df_2016 = grunnkrets_norway[grunnkrets_norway[\"year\"] == 2016]\n",
    "bus_df = bus_stops_lat_lon(busstops)\n",
    "stores_gk = impude_NaN(stores_train, grunnkrets_norway, NaN_string=\"district_name\")\n",
    "stores_age = impude_NaN(stores_train, grunnkrets_age, NaN_string= \"age_0\")\n",
    "\n",
    "\n",
    "pop_count_df = population_count_grouped_by_geo_group(grunnkrets_age, grunnkrets_norway, stores_impuded)\n",
    "age_dist_df = age_dist_by_geo_group(stores_gk, grunnkrets_age, grunnkrets_norway)\n",
    "house_hold_dist = household_dist_by_geo_group(grunnkrets_household, grunnkrets_norway, stores_gk)\n",
    "pop_per_store_type = population_per_store_type_grouped_by_geo_groups(stores_train, plaace_hierarchy, grunnkrets_norway, grunnkrets_age, stores_gk, geo_groups=geo, store_types=store, agg_string=\"pop_per_num_stores\")\n",
    "pop_density = population_density_grouped_by_geo_group(grunnkrets_age, grunnkrets_norway, stores_gk)\n",
    "is_mall_df = is_mall_only(stores_train)\n",
    "is_chain_df = is_chain_only(stores_train)\n",
    "store_types_count = store_types_all_count_by_geo_groups(stores_train, plaace_hierarchy, grunnkrets_df_2016, stores_gk, store_types=store, geo_groups=geo)\n",
    "#store_types_revenue = store_types_all_revenue_by_geo_groups(stores_all_df, plaace_hierarchy, grunnkrets_df_2016, store_types=store, geo_groups=geo)\n",
    "store_radius = stores_in_radius_by_type(stores_all_df, plaace_hierarchy, store_types=store, radius = 0.1)\n",
    "busstop_distance = bus_stops_distance_by_importance(stores_all_df, bus_df, stop_importance_levels = importance_levels)\n",
    "busstop_radius = bus_stops_in_radius_by_importance(stores_all_df, bus_df, stop_importance_levels=importance_levels, radius = 0.1)\n",
    "\n",
    "df = (pop_count_df.merge(age_dist_df, how = \"left\", on = \"store_id\")\n",
    "    .merge(house_hold_dist, how = \"left\", on =\"store_id\")\n",
    "    .merge(pop_per_store_type, how = \"left\", on = \"store_id\")\n",
    "    .merge(pop_density, how = \"left\", on  = \"store_id\")\n",
    "    .merge(is_mall_df, how = \"left\", on = \"store_id\")\n",
    "    .merge(is_chain_df, how = \"left\", on = \"store_id\")\n",
    "    #.merge(income_df, how = \"left\", on = \"store_id\")\n",
    "    .merge(store_types_count, how =\"left\", on = \"store_id\")\n",
    "    #.merge(store_types_revenue, how = \"left\", on = \"store_id\")\n",
    "    .merge(id_and_revenue_df, how = \"left\", on = \"store_id\")\n",
    "    .merge(store_radius, how = \"left\", on = \"store_id\")\n",
    "    .merge(busstop_distance,how = \"left\", on = \"store_id\")\n",
    "    .merge(busstop_radius, how =\"left\", on =\"store_id\" )\n",
    ")\n",
    "\n",
    "#df.to_csv(\"dataset_train_2.csv\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging of stores_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store =[\"lv1_desc\", \"lv2_desc\", \"lv3_desc\", \"lv4_desc\"]\n",
    "geo= [\"grunnkrets_id\", \"district_name\", \"municipality_name\"]\n",
    "importance_levels = [\"Mangler viktighetsnivå\", \"Standard holdeplass\", \"Lokalt knutepunkt\",\"Regionalt knutepunkt\", \"Annen viktig holdeplass\", \"Nasjonalt knutepunkt\"]\n",
    "grunnkrets_df_2016 = grunnkrets_norway[grunnkrets_norway[\"year\"] == 2016]\n",
    "bus_df = bus_stops_lat_lon(busstops)\n",
    "\n",
    "pop_count_df = population_count_grouped_by_geo_group(stores_test, grunnkrets_age, grunnkrets_norway)\n",
    "age_dist_df = age_dist_by_geo_group(stores_test, grunnkrets_age, grunnkrets_norway)\n",
    "house_hold_dist = household_dist_by_geo_group(stores_test, grunnkrets_household, grunnkrets_norway)\n",
    "pop_per_store_type = population_per_store_type_grouped_by_geo_groups(stores_test, plaace_hierarchy, grunnkrets_norway, grunnkrets_age, geo_groups=geo, store_types=store, agg_string=\"pop_per_num_stores\")\n",
    "pop_density = population_density_grouped_by_geo_group(stores_test, grunnkrets_age, grunnkrets_norway)\n",
    "is_mall_df = is_mall_only(stores_test)\n",
    "is_chain_df = is_chain_only(stores_test)\n",
    "store_types_count = store_types_all_count_by_geo_groups(stores_test, plaace_hierarchy, grunnkrets_df_2016, store_types=store, geo_groups=geo)\n",
    "#store_types_revenue = store_types_all_revenue_by_geo_groups(stores_test, plaace_hierarchy, grunnkrets_df_2016, store_types=store, geo_groups=geo)\n",
    "store_radius = stores_in_radius_by_type(stores_test, plaace_hierarchy, store_types=store, radius = 0.1)\n",
    "busstop_distance = bus_stops_distance_by_importance(stores_test, bus_df, stop_importance_levels = importance_levels)\n",
    "busstop_radius = bus_stops_in_radius_by_importance(stores_test, bus_df, stop_importance_levels=importance_levels, radius = 0.1)\n",
    "\n",
    "df = (pop_count_df.merge(age_dist_df, how = \"left\", on = \"store_id\")\n",
    "    .merge(house_hold_dist, how = \"left\", on =\"store_id\")\n",
    "    .merge(pop_per_store_type, how = \"left\", on = \"store_id\")\n",
    "    .merge(pop_density, how = \"left\", on  = \"store_id\")\n",
    "    .merge(is_mall_df, how = \"left\", on = \"store_id\")\n",
    "    .merge(is_chain_df, how = \"left\", on = \"store_id\")\n",
    "    #.merge(income_df, how = \"left\", on = \"store_id\")\n",
    "    .merge(store_types_count, how =\"left\", on = \"store_id\")\n",
    "    #.merge(store_types_revenue, how = \"left\", on = \"store_id\")\n",
    "    #.merge(id_and_revenue_df, how = \"left\", on = \"store_id\")\n",
    "    .merge(store_radius, how = \"left\", on = \"store_id\")\n",
    "    .merge(busstop_distance,how = \"left\", on = \"store_id\")\n",
    "    .merge(busstop_radius, how =\"left\", on =\"store_id\" )\n",
    ")\n",
    "\n",
    "#df.to_csv(\"dataset_test_1.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "store_id                                    0\n",
       "year                                        0\n",
       "store_name                                  0\n",
       "plaace_hierarchy_id                         0\n",
       "sales_channel_name                          0\n",
       "grunnkrets_id                               0\n",
       "address                                  1774\n",
       "lat                                         0\n",
       "lon                                         0\n",
       "chain_name                               9122\n",
       "mall_name                               10579\n",
       "revenue                                     0\n",
       "couple_children_0_to_5_years                0\n",
       "couple_children_18_or_above                 0\n",
       "couple_children_6_to_17_years               0\n",
       "couple_without_children                     0\n",
       "single_parent_children_0_to_5_years         0\n",
       "single_parent_children_18_or_above          0\n",
       "single_parent_children_6_to_17_years        0\n",
       "singles                                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def impude_NaN (stores_df, grunnkrets_df, NaN_string ): \n",
    "    geo_df = grunnkrets_df[grunnkrets_df[\"year\"] == 2016]\n",
    "    geo_df2 = geo_df.drop(\"year\", axis = 1)\n",
    "    merged_df = stores_df.merge(geo_df2, how = \"left\", on = \"grunnkrets_id\")\n",
    "    NaN_df = merged_df[merged_df[NaN_string].isna()]\n",
    "    split_df = merged_df[merged_df[NaN_string].notna()]\n",
    "\n",
    "    mat = cdist(NaN_df[['lat', 'lon']],\n",
    "                split_df[['lat', 'lon']], metric='euclidean')\n",
    "\n",
    "    new_df = pd.DataFrame(mat, index= NaN_df['grunnkrets_id'], columns=split_df['grunnkrets_id'])\n",
    "\n",
    "    grunnkrets_id = NaN_df.grunnkrets_id\n",
    "    closest = new_df.idxmin(axis=1)\n",
    "    distance = new_df.min(axis=1)\n",
    "\n",
    "    closest_df_with_distance = pd.DataFrame({\"grunnkrets_id\": grunnkrets_id, \"closest_valid_id\" : closest.values, \"distance\": distance.values})\n",
    "    closest_df = pd.DataFrame({\"grunnkrets_id\": grunnkrets_id, \"closest_valid_id\" : closest.values})\n",
    "\n",
    "    df_with_values_from_valid_id = split_df[split_df[\"grunnkrets_id\"].isin(closest.values)]\n",
    "    df_with_values_from_valid_id_removed_duplicates = df_with_values_from_valid_id.drop_duplicates(subset = [\"grunnkrets_id\"])\n",
    "\n",
    "    df_valid_geo_data = df_with_values_from_valid_id_removed_duplicates.iloc[:,12:]\n",
    "    df_with_only_gk_id = df_with_values_from_valid_id_removed_duplicates[[\"grunnkrets_id\"]]\n",
    "    df_list = [df_with_only_gk_id,df_valid_geo_data ]\n",
    "    df_valid_geo_data_and_id = pd.concat(df_list, axis=1)\n",
    "\n",
    "    df_without_nan = NaN_df.iloc[:,:12]\n",
    "\n",
    "    df_including_closest_valid_id = df_without_nan.reset_index().merge(closest_df, how = \"left\", on = \"grunnkrets_id\").set_index(\"index\")\n",
    "\n",
    "    df_impuded = df_including_closest_valid_id.reset_index().merge(df_valid_geo_data_and_id, how=\"left\", left_on =\"closest_valid_id\", right_on=\"grunnkrets_id\").set_index(\"index\")\n",
    "    df_impuded_without_duplicates = df_impuded.drop_duplicates(subset=\"store_id\")\n",
    "\n",
    "    new_df_impuded = df_impuded_without_duplicates.drop([\"closest_valid_id\", \"grunnkrets_id_y\"], axis = 1).rename(columns= {\"grunnkrets_id_x\": \"grunnkrets_id\"})\n",
    "\n",
    "\n",
    "    impuded = pd.concat([split_df, new_df_impuded])\n",
    "\n",
    "    return impuded\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "4293deecdc7c3795ee566a191d4f502a35db2bbb6b972059f78dba08f27ad354"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
